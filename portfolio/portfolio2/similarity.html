<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<title>Portfolio 2 - Similarity Metrics</title>
		<meta name="author" content="Oliver"/>
	</head>
	<body>
		<h1>Similarity Metrics</h1>
		<div id="Content">
			<div id="Intro">
				<h2>Why Do We Care?</h2>
				<p>Is a cow similar to a buffalo?  Probably.  Is a MP3 similar to a piece of celery?  Probably not.  But how about comparing a customer who bought eggs and milk to a customer who bought egg substitute and baby formula?  Later on we'll cover algorithms that will depend heavily on knowing how similar things are to one another, and this can't be a vague "well, they're both large, four-legged critters" type reasoning.  It has to be quantifiable, so we come up with similarity metrics to at least attempt to take the guesswork out of the process.</p>
			</div> <!--end of intro-->
			<div id="Metrics">
				<h2>How Do We Do It?</h2>
				<p>Luckily for us, there are several well established similarity metrics already in existence that can be used to compare various types of objects, each with its own strengths and weaknesses.  Here's a few, and an implementation in Ruby, or you could always create your own!  (As a couple in our class did for a CSCI522 project.)</p>
				<div id="SMC">
					<h3>Simple Matching Coefficient</h3>
					<p>The Simple Matching Coefficient (SMC) is ... well, simple.  All you do is check your data objects for areas where they match.  Say you have a person, Bob, with the original Star Wars trilogy and another person, John, who owns them too but also made the mistake of purchasing the new prequel trilogy.  If you consider the ownership of each film to be one attribute, then the Bob's ownership vector could be represented as <0, 0, 0, 1, 1, 1> and John's as <1, 1, 1, 1, 1, 1>.  SMC then observes that the first three attributes (the prequel trilogy) does not match, but the following three do match.  Thus, we have 3 matches out of 6 attributes, for a similarity result of 3/6 = <strong>0.5</strong>.</p>
					<pre>
def smc(object1, object2)
  if object1.values.length != object2.values.length
    return "SMC can't be calculated as objects have a different number of values!"
  else
    length = object1.values.length
    denom = length.to_f
    matchCount = 0
    for i in (0...length)
      if(object1.values[i] == object2.values[i])
        matchCount = matchCount + 1
      end
    end
    result = matchCount / denom
  end
  
  puts "SMC is #{result}!"
  return result
end
					</pre>
					<p>SMC is great for what it is: a quick and easy way to compare objects where we just care about the values that are equal.  It won't work for continuous, or even non-nominal, data, but is great for binary fields.</p>
				</div> <!-- end of SMC-->
				<div id="Jaccard">
					<h3>Jaccard Coefficient</h3>
					<p>The Jaccard Coefficient is very similar to SMC, with only one difference: It doesn't care about the absence of values missing in both objects.  SMC may assume that two very different objects are very similar because they have a large number of areas in which both <em>lack</em> a value, instead of the presence of areas where they <em>share</em> a value.  Using the Star Wars example again, if we were part of a much larger movie system like Netflix, there would be thousands of videos in each person's ownership vector.  And almost every space would be a 0.  In other words, their vectors would be like this one: <0 or 1, 0 or 1, 0 or 1, 1, 1, 1, 0, 0, 0, ...(100000x)...,0,0>.  SMC would see this as near perfect similarity as both people have matching zeros all over the place.  Both people own 3 or 6 Star Wars films, but they both lack the millions of other possible movies in the database.  But in this case it's the movies you actually own, not the ones you don't own, that matter, and these two people should be viewed differently (general sci-fi lover vs. Star Wars nut).  So Jaccard goes ahead and completely ignores all the romance and western films and just compares the six Star Wars films, again coming up with 0.5 for the similarity score.  (Yes, it's the same number, but with a lot more films being compared.  SMC is now close to 1.)</p>
					<pre>
def jaccard(object1, object2)
  if object1.values.length != object2.values.length
    return "Jaccard can't be calculated as objects have a different number of values!"
  else
    length = object1.values.length
    denom = length.to_f
    matchCount = 0
    for i in (0...length)
      if(object1.values[i] == object2.values[i])
        if(object1.values[i] != 0)
          matchCount = matchCount + 1
        end
      end
    end
    result = matchCount / denom
  end
  
  puts "Jaccard Similarity is #{result}!"
return result
end
					</pre>
					<p>In general, Jaccard can be used anywhere where SMC is, just with possibly better results.</p>
				</div> <!-- end of Jaccard-->
				<div id="Euclidean">
					<h3>Euclidean Distance</h3>
					<p>You probably already know all about Euclidean Distance, but you may not know it.  This is basically the "distance formula" covered in high school algebra.  In case you don't remember, the distance is the square root of the sum of the squares of the sides in each direction.  In two dimensions, this is the same as the Pythagorean Theorem, but the math still works out in higher dimensions as well.  The only problem is that we would prefer the similarity metric to return scores between 0 (dissimilar) and 1 (perfectly similar).  Euclidean Distance, as described, would return high values for very dissimilar objects and 0 for a perfect match.  To solve this problem, we just normalize the score by returning 1/(1+distance).  This way large distances head toward 0 and perfect matches with no distance come out as 1, as we'd want.  If your attributes have wildly varying scales, the larger scales have greater potential to affect the result, so you may want to scale them similarly in preprocessing.</p>
					<pre>
def euclidean(object1, object2)
  if object1.values.length != object2.values.length
    return "Euclidean Distance can't be calculated as objects have a different number of values!"
  else
    length = object1.values.length
    result = 0
    for i in (0...length)
      result = result + (object1.values[i]-object2.values[i])**2
    end
    result = Math.sqrt(result)
  end
  
  #normalizing!
  result = 1 / (1 + result.to_f)

  puts "Euclidean distance is #{result}!"
  return result
end
					</pre>
					<p>Euclidean Distance works well for continuous attributes, but very poorly for binary.  Why?  Because squaring and square rooting a differences of 0 or 1 don't provide very interesting results.  SMC or Jaccard would be better for these, but Euclidean Distance is great for combining differences of many attributes into one value.</p>
				</div> <!-- end of Euclidean-->
			</div> <!-- end of metrics-->
		</div> <!--end of content-->
		<div class="MoreInfo">
			<h2>More Information</h2>
			<p>See section 2.4 of <em>Introduction to Data Mining</em> by Tan, Steinbach, and Kumar, 2006.</p>
		</div> <!--end of MoreInfo-->
		<div class="Copyright">
			<p>&copy; 2011 by Oliver Chase. All rights reserved.</p>
		</div>
	</body>
</html>